# Documentaci√≥n Consolidada - LTI ATS Backlog

Este documento consolida toda la documentaci√≥n de Product Backlog del proyecto LTI ATS.

---

# Parte 1: User Stories - LTI ATS

## Plantilla Utilizada

Todas las User Stories siguen esta plantilla est√°ndar:

```
## US-[ID]: [T√≠tulo]

**Como** [rol del usuario]
**Quiero** [acci√≥n/funcionalidad deseada]
**Para** [beneficio/valor que obtiene]

### Descripci√≥n
[Contexto adicional y detalles de la historia]

### Criterios de Aceptaci√≥n
- [ ] [Criterio verificable 1]
- [ ] [Criterio verificable 2]
- [ ] [Criterio verificable N]

### Notas T√©cnicas
[Consideraciones de implementaci√≥n, dependencias, etc.]

### Definici√≥n de Done (DoD)
- [ ] C√≥digo implementado y revisado (code review)
- [ ] Tests unitarios escritos y pasando (>80% cobertura)
- [ ] Tests de integraci√≥n pasando
- [ ] Documentaci√≥n actualizada
- [ ] Desplegado en ambiente de staging
- [ ] Aprobaci√≥n del Product Owner

### Mockups/Wireframes
[Referencias visuales si aplica]

### Dependencias
[Otras US o componentes necesarios]

### Prioridad: [Alta/Media/Baja]
### Estimaci√≥n: [Puntos de historia]
```

---

## User Stories del Sistema LTI

---

## US-001: Creaci√≥n de Ofertas de Empleo con Asistencia de IA

**Como** Recruiter
**Quiero** crear ofertas de empleo con asistencia de inteligencia artificial
**Para** generar descripciones optimizadas en menos tiempo y con mejor calidad

### Descripci√≥n
El recruiter necesita poder crear nuevas ofertas de empleo de manera eficiente. El sistema debe proporcionar asistencia de IA que genere autom√°ticamente la descripci√≥n del puesto, requisitos y beneficios bas√°ndose en el t√≠tulo del puesto y algunos par√°metros b√°sicos. El recruiter debe poder editar y personalizar el contenido generado antes de publicar.

### Criterios de Aceptaci√≥n
- [ ] El usuario puede acceder al formulario de creaci√≥n de oferta desde el dashboard principal
- [ ] Al ingresar el t√≠tulo del puesto, el sistema sugiere una categor√≠a/departamento
- [ ] Existe un bot√≥n "Generar con IA" que activa la generaci√≥n autom√°tica
- [ ] La IA genera: descripci√≥n del puesto, requisitos (m√≠nimos y deseables), beneficios
- [ ] El contenido generado se muestra en campos editables
- [ ] El usuario puede regenerar secciones individuales si no est√° satisfecho
- [ ] El sistema guarda borradores autom√°ticamente cada 30 segundos
- [ ] La oferta puede guardarse como borrador o publicarse directamente
- [ ] El tiempo de generaci√≥n de IA no excede 10 segundos
- [ ] Se muestra indicador de carga durante la generaci√≥n

### Notas T√©cnicas
- Integraci√≥n con AI Service (Content Generator component)
- Uso de LangChain para orquestaci√≥n de prompts
- Almacenamiento en PostgreSQL (tabla `job_posting`)
- Endpoint: `POST /api/v1/jobs` y `POST /api/v1/jobs/{id}/generate`
- Cache de respuestas frecuentes en Redis para optimizar costos LLM

### Definici√≥n de Done (DoD)
- [ ] C√≥digo implementado y revisado (code review)
- [ ] Tests unitarios escritos y pasando (>80% cobertura)
- [ ] Tests de integraci√≥n pasando
- [ ] Documentaci√≥n de API actualizada (OpenAPI)
- [ ] Desplegado en ambiente de staging
- [ ] Aprobaci√≥n del Product Owner
- [ ] M√©tricas de uso de IA configuradas en Prometheus

### Mockups/Wireframes
- Wireframe del formulario de creaci√≥n con bot√≥n de IA
- Estado de loading durante generaci√≥n
- Vista de edici√≥n post-generaci√≥n

### Dependencias
- Infrastructure: AI Service desplegado
- Data: Prompts de generaci√≥n configurados en Prompt Manager
- Auth: Sistema de autenticaci√≥n funcional

### Prioridad: Alta
### Estimaci√≥n: 13 puntos de historia

---

## US-002: Visualizaci√≥n de Pipeline de Candidatos en Kanban

**Como** Recruiter
**Quiero** visualizar y gestionar candidatos en un tablero Kanban
**Para** tener una vista clara del estado de cada candidato y moverlos entre etapas f√°cilmente

### Descripci√≥n
El sistema debe proporcionar una vista tipo Kanban donde el recruiter pueda ver todos los candidatos de una oferta organizados por etapas del pipeline (Applied, Screening, Interview, Offer, Hired/Rejected). Los candidatos deben poder moverse entre columnas mediante drag & drop, y cada tarjeta debe mostrar informaci√≥n resumida del candidato incluyendo su AI Score.

### Criterios de Aceptaci√≥n
- [ ] El tablero Kanban muestra todas las etapas del pipeline configuradas para la oferta
- [ ] Cada candidato se representa como una tarjeta con: nombre, foto, AI Score, fecha de aplicaci√≥n
- [ ] El AI Score se muestra con c√≥digo de colores (verde >70, amarillo 40-70, rojo <40)
- [ ] Las tarjetas pueden arrastrarse y soltarse entre columnas
- [ ] Al mover una tarjeta, se actualiza el estado en tiempo real
- [ ] Se muestra un contador de candidatos por columna
- [ ] Existe filtro por AI Score (rango), fecha de aplicaci√≥n y fuente
- [ ] El tablero se actualiza en tiempo real cuando otro usuario hace cambios
- [ ] Se puede cambiar entre vista Kanban, Lista y Tabla
- [ ] Al hacer clic en una tarjeta, se abre el perfil detallado del candidato

### Notas T√©cnicas
- Frontend: React con react-beautiful-dnd para drag & drop
- WebSocket (Socket.io) para actualizaciones en tiempo real
- Estado optimista para mejor UX al mover tarjetas
- Endpoint: `GET /api/v1/jobs/{id}/pipeline`, `PATCH /api/v1/applications/{id}/stage`
- Collaboration Service para sincronizaci√≥n entre usuarios

### Definici√≥n de Done (DoD)
- [ ] C√≥digo implementado y revisado (code review)
- [ ] Tests unitarios escritos y pasando (>80% cobertura)
- [ ] Tests E2E para flujo de drag & drop
- [ ] Performance: renderizado <100ms para 100 candidatos
- [ ] Documentaci√≥n actualizada
- [ ] Desplegado en ambiente de staging
- [ ] Aprobaci√≥n del Product Owner

### Mockups/Wireframes
- Dise√±o del tablero Kanban con columnas
- Dise√±o de tarjeta de candidato
- Estados de hover y dragging

### Dependencias
- US-005: Sistema de scoring de candidatos
- US-003: Gesti√≥n b√°sica de candidatos
- Collaboration Service operativo

### Prioridad: Alta
### Estimaci√≥n: 8 puntos de historia

---

## US-003: Aplicaci√≥n de Candidatos y Parsing de CV con IA

**Como** Candidato
**Quiero** aplicar a una oferta subiendo mi CV
**Para** que mis datos sean procesados autom√°ticamente sin tener que llenar formularios extensos

### Descripci√≥n
Los candidatos deben poder aplicar a ofertas de empleo subiendo su CV. El sistema utilizar√° IA para extraer autom√°ticamente la informaci√≥n relevante (datos de contacto, experiencia laboral, educaci√≥n, habilidades) y completar el perfil del candidato. Esto reduce la fricci√≥n en el proceso de aplicaci√≥n y mejora la experiencia del candidato.

### Criterios de Aceptaci√≥n
- [ ] El candidato puede acceder a la p√°gina de aplicaci√≥n desde la oferta p√∫blica
- [ ] Puede subir CV en formatos: PDF, DOCX, DOC (m√°x. 5MB)
- [ ] El sistema muestra barra de progreso durante el procesamiento
- [ ] El CV es parseado y se extraen: nombre, email, tel√©fono, LinkedIn, experiencia, educaci√≥n, habilidades
- [ ] Los datos extra√≠dos se muestran al candidato para confirmaci√≥n/edici√≥n
- [ ] El candidato puede corregir datos incorrectos antes de enviar
- [ ] Se solicita consentimiento GDPR expl√≠cito antes de completar la aplicaci√≥n
- [ ] El candidato recibe email de confirmaci√≥n al completar la aplicaci√≥n
- [ ] Si el parsing falla, se muestra formulario manual como fallback
- [ ] El tiempo de parsing no excede 15 segundos

### Notas T√©cnicas
- AI Service: CV Parser component (spaCy + LLM)
- Almacenamiento de documentos en S3 con cifrado
- Endpoint: `POST /api/v1/public/applications`
- Generaci√≥n de embeddings para b√∫squeda sem√°ntica posterior
- Evento Kafka `cv.uploaded` para procesamiento as√≠ncrono
- Tabla `candidate_profile` para datos estructurados

### Definici√≥n de Done (DoD)
- [ ] C√≥digo implementado y revisado (code review)
- [ ] Tests unitarios escritos y pasando (>80% cobertura)
- [ ] Tests de integraci√≥n con AI Service
- [ ] Validaci√≥n de seguridad (sanitizaci√≥n de archivos)
- [ ] Documentaci√≥n actualizada
- [ ] Desplegado en ambiente de staging
- [ ] Aprobaci√≥n del Product Owner

### Mockups/Wireframes
- P√°gina de aplicaci√≥n con upload de CV
- Vista de confirmaci√≥n de datos extra√≠dos
- Email de confirmaci√≥n

### Dependencias
- AI Service: CV Parser operativo
- Storage: S3 bucket configurado
- Email Service: Templates configurados

### Prioridad: Alta
### Estimaci√≥n: 13 puntos de historia

---

## US-004: Programaci√≥n Autom√°tica de Entrevistas

**Como** Recruiter
**Quiero** que el sistema coordine autom√°ticamente la programaci√≥n de entrevistas
**Para** eliminar el trabajo manual de encontrar horarios compatibles entre candidato y entrevistadores

### Descripci√≥n
El sistema debe integrar los calendarios de los entrevistadores (Google Calendar, Outlook) y proponer autom√°ticamente horarios disponibles al candidato. El candidato selecciona su horario preferido y el sistema crea el evento en todos los calendarios, env√≠a confirmaciones y configura recordatorios autom√°ticos.

### Criterios de Aceptaci√≥n
- [ ] El recruiter puede seleccionar candidato y tipo de entrevista (phone, video, onsite)
- [ ] El recruiter asigna entrevistadores al proceso
- [ ] El sistema consulta disponibilidad de calendarios conectados
- [ ] Se calculan slots √≥ptimos considerando zonas horarias de todos los participantes
- [ ] Se presentan al recruiter los 5 mejores slots disponibles
- [ ] El recruiter aprueba el env√≠o de propuesta al candidato
- [ ] El candidato recibe link con opciones de horario
- [ ] El candidato puede seleccionar su preferencia
- [ ] Al confirmar, se crean eventos en todos los calendarios
- [ ] Se env√≠an confirmaciones con link de videoconferencia (Zoom/Teams/Meet)
- [ ] Se programan recordatorios autom√°ticos (24h y 1h antes)
- [ ] Si el candidato no responde en 48h, se env√≠a reminder autom√°tico

### Notas T√©cnicas
- Scheduling Service con Temporal para workflows
- Integraci√≥n OAuth con Google Calendar y Microsoft Graph API
- Endpoint: `POST /api/v1/interviews/schedule`
- Manejo de zonas horarias con moment-timezone
- Generaci√≥n de links de videoconferencia v√≠a API (Zoom/Teams)
- Eventos Kafka para notificaciones

### Definici√≥n de Done (DoD)
- [ ] C√≥digo implementado y revisado (code review)
- [ ] Tests unitarios escritos y pasando (>80% cobertura)
- [ ] Tests de integraci√≥n con APIs de calendario
- [ ] Manejo de errores para calendarios desconectados
- [ ] Documentaci√≥n actualizada
- [ ] Desplegado en ambiente de staging
- [ ] Aprobaci√≥n del Product Owner

### Mockups/Wireframes
- Modal de programaci√≥n de entrevista
- Email de propuesta al candidato
- P√°gina de selecci√≥n de horario para candidato
- Evento de calendario creado

### Dependencias
- Integraciones: Google Calendar OAuth, Microsoft Graph API
- Notification Service operativo
- Configuraci√≥n de Zoom/Teams/Meet API

### Prioridad: Alta
### Estimaci√≥n: 21 puntos de historia

---

## US-005: Scoring Autom√°tico de Candidatos con IA

**Como** Recruiter
**Quiero** que el sistema calcule autom√°ticamente un score de match para cada candidato
**Para** priorizar mi tiempo en los candidatos m√°s relevantes para el puesto

### Descripci√≥n
Cuando un candidato aplica a una oferta, el sistema debe calcular autom√°ticamente un score de 0-100 que represente qu√© tan bien encaja el candidato con los requisitos del puesto. El score debe considerar skills, experiencia, educaci√≥n y fit cultural. El recruiter debe poder ver el desglose del score y entender por qu√© el candidato recibi√≥ esa puntuaci√≥n.

### Criterios de Aceptaci√≥n
- [ ] El score se calcula autom√°ticamente tras el parsing del CV
- [ ] El score general es un n√∫mero de 0-100
- [ ] Se muestra desglose en 4 categor√≠as: Skills Match, Experience Match, Education Match, Cultural Fit
- [ ] Cada categor√≠a tiene score individual y explicaci√≥n en texto
- [ ] Se listan skills coincidentes, faltantes y adicionales
- [ ] El score se actualiza si se modifica el CV o los requisitos del puesto
- [ ] Los candidatos se pueden ordenar por score en cualquier vista
- [ ] El c√°lculo de score no excede 30 segundos tras la aplicaci√≥n
- [ ] Se genera un resumen ejecutivo de 2-3 oraciones sobre el candidato
- [ ] El recruiter puede dar feedback sobre la precisi√≥n del score (üëç/üëé)

### Notas T√©cnicas
- AI Service: Candidate Scorer component
- Uso de embeddings (OpenAI/Cohere) para matching sem√°ntico
- Vector DB (Pinecone) para b√∫squeda de similitud
- Almacenamiento en tabla `ai_score`
- Evento Kafka `score.calculated` para notificaciones
- Endpoint: `GET /api/v1/applications/{id}/score`
- M√©tricas de feedback para mejora continua del modelo

### Definici√≥n de Done (DoD)
- [ ] C√≥digo implementado y revisado (code review)
- [ ] Tests unitarios escritos y pasando (>80% cobertura)
- [ ] Tests de integraci√≥n con AI Service
- [ ] Benchmarks de precisi√≥n vs evaluaci√≥n manual
- [ ] Documentaci√≥n actualizada
- [ ] Desplegado en ambiente de staging
- [ ] Aprobaci√≥n del Product Owner

### Mockups/Wireframes
- Tarjeta de score en perfil de candidato
- Vista expandida con desglose de categor√≠as
- Iconograf√≠a para skills match/missing

### Dependencias
- US-003: Parsing de CV implementado
- AI Service: Embeddings y Vector DB operativos
- Prompts de scoring configurados

### Prioridad: Alta
### Estimaci√≥n: 21 puntos de historia

---

## US-006: Evaluaci√≥n Colaborativa con Scorecards

**Como** Hiring Manager
**Quiero** completar scorecards de evaluaci√≥n estructuradas despu√©s de entrevistar candidatos
**Para** proporcionar feedback consistente y facilitar la comparaci√≥n entre candidatos

### Descripci√≥n
Despu√©s de cada entrevista, los evaluadores deben poder completar una scorecard con criterios predefinidos. Cada criterio tiene una escala de puntuaci√≥n y espacio para notas. Las scorecards permiten evaluar de manera consistente y generar una puntuaci√≥n agregada para comparar candidatos.

### Criterios de Aceptaci√≥n
- [ ] Existe un cat√°logo de scorecards configurables por tipo de entrevista
- [ ] Cada scorecard tiene criterios con nombre, descripci√≥n y peso
- [ ] Los criterios se punt√∫an en escala 1-5 con etiquetas descriptivas
- [ ] Cada criterio tiene campo opcional para notas
- [ ] El evaluador puede a√±adir una recomendaci√≥n final: Strong Hire, Hire, No Hire, Strong No Hire
- [ ] Se puede a√±adir un comentario general sobre la entrevista
- [ ] La scorecard se guarda autom√°ticamente (autosave)
- [ ] Al completar, se notifica al recruiter responsable
- [ ] El recruiter puede ver todas las scorecards de un candidato en un panel consolidado
- [ ] Se calcula score promedio ponderado autom√°ticamente

### Notas T√©cnicas
- Tablas: `scorecard`, `scorecard_criteria`, `evaluation`, `evaluation_score`
- Endpoint: `POST /api/v1/evaluations`, `GET /api/v1/applications/{id}/evaluations`
- WebSocket para notificaciones en tiempo real
- C√°lculo de promedio ponderado en el frontend y backend

### Definici√≥n de Done (DoD)
- [ ] C√≥digo implementado y revisado (code review)
- [ ] Tests unitarios escritos y pasando (>80% cobertura)
- [ ] Tests de integraci√≥n
- [ ] Documentaci√≥n actualizada
- [ ] Desplegado en ambiente de staging
- [ ] Aprobaci√≥n del Product Owner

### Mockups/Wireframes
- Formulario de scorecard
- Vista de panel consolidado de evaluaciones
- Comparativa visual entre candidatos

### Dependencias
- US-004: Sistema de entrevistas
- Notification Service operativo

### Prioridad: Media
### Estimaci√≥n: 13 puntos de historia

---

## US-007: Colaboraci√≥n en Tiempo Real en Perfiles de Candidatos

**Como** Miembro del equipo de contrataci√≥n
**Quiero** ver en tiempo real qui√©n est√° viendo el perfil de un candidato y sus comentarios
**Para** colaborar eficientemente y evitar duplicar esfuerzos o tomar decisiones desinformadas

### Descripci√≥n
Inspirado en herramientas como Figma y Notion, el sistema debe mostrar presencia en tiempo real (avatares de qui√©n est√° viendo el mismo perfil), comentarios contextuales con menciones, y actualizaciones instant√°neas sin necesidad de refrescar la p√°gina.

### Criterios de Aceptaci√≥n
- [ ] Al abrir un perfil de candidato, se muestran avatares de otros usuarios vi√©ndolo
- [ ] Los avatares muestran nombre al hacer hover
- [ ] Se pueden a√±adir comentarios en cualquier secci√≥n del perfil
- [ ] Los comentarios soportan @menciones a otros usuarios del equipo
- [ ] Las menciones generan notificaciones al usuario mencionado
- [ ] Los comentarios aparecen en tiempo real sin refrescar
- [ ] Se puede responder a comentarios (threads)
- [ ] Existe un feed de actividad con el historial de acciones
- [ ] Las acciones (mover de etapa, a√±adir evaluaci√≥n) se reflejan instant√°neamente
- [ ] El sistema funciona correctamente con hasta 10 usuarios simult√°neos en el mismo perfil

### Notas T√©cnicas
- Collaboration Service con Socket.io
- Redis para estado de presencia
- Tabla `comment` con soporte para threads (parent_id)
- Eventos: user.joined, user.left, comment.added, action.performed
- Endpoint: `POST /api/v1/applications/{id}/comments`

### Definici√≥n de Done (DoD)
- [ ] C√≥digo implementado y revisado (code review)
- [ ] Tests unitarios escritos y pasando (>80% cobertura)
- [ ] Tests de integraci√≥n con WebSocket
- [ ] Load testing con 10 usuarios simult√°neos
- [ ] Documentaci√≥n actualizada
- [ ] Desplegado en ambiente de staging
- [ ] Aprobaci√≥n del Product Owner

### Mockups/Wireframes
- Indicadores de presencia en perfil
- Componente de comentarios
- Notificaci√≥n de menci√≥n

### Dependencias
- Collaboration Service desplegado
- Notification Service operativo
- WebSocket infrastructure

### Prioridad: Media
### Estimaci√≥n: 21 puntos de historia

---

## US-008: Panel de Decisi√≥n Colaborativa

**Como** Hiring Manager
**Quiero** facilitar una sesi√≥n de decisi√≥n estructurada con todo el equipo
**Para** tomar decisiones de contrataci√≥n informadas y documentadas basadas en consenso

### Descripci√≥n
Cuando un candidato ha completado todas las entrevistas, el sistema debe proporcionar un panel de decisi√≥n donde todos los evaluadores puedan votar simult√°neamente, ver un resumen de todas las evaluaciones, discutir puntos importantes y llegar a una decisi√≥n final documentada.

### Criterios de Aceptaci√≥n
- [ ] El Hiring Manager puede iniciar una sesi√≥n de decisi√≥n para un candidato
- [ ] Se invita autom√°ticamente a todos los que han evaluado al candidato
- [ ] El panel muestra resumen de: AI Score, scores de cada evaluador, recomendaciones
- [ ] Se presenta comparativa visual con otros candidatos finalistas (si aplica)
- [ ] Cada participante puede votar: Hire / No Hire / Need More Info
- [ ] Los votos se muestran en tiempo real (an√≥nimos hasta que todos voten, opcionalmente)
- [ ] Existe chat integrado para discusi√≥n
- [ ] El Hiring Manager puede registrar la decisi√≥n final y justificaci√≥n
- [ ] La decisi√≥n se guarda en el historial del candidato
- [ ] Se generan autom√°ticamente las notificaciones/emails seg√∫n la decisi√≥n

### Notas T√©cnicas
- Collaboration Service para sincronizaci√≥n en tiempo real
- Nuevo endpoint: `POST /api/v1/applications/{id}/decision-session`
- WebSocket events para votos y chat
- Almacenamiento de decisi√≥n en tabla `application` (status) y nuevo registro en audit

### Definici√≥n de Done (DoD)
- [ ] C√≥digo implementado y revisado (code review)
- [ ] Tests unitarios escritos y pasando (>80% cobertura)
- [ ] Tests de integraci√≥n
- [ ] Documentaci√≥n actualizada
- [ ] Desplegado en ambiente de staging
- [ ] Aprobaci√≥n del Product Owner

### Mockups/Wireframes
- Panel de decisi√≥n con resumen de evaluaciones
- Sistema de votaci√≥n
- Chat integrado
- Registro de decisi√≥n final

### Dependencias
- US-006: Scorecards implementadas
- US-007: Colaboraci√≥n en tiempo real
- Notification Service operativo

### Prioridad: Media
### Estimaci√≥n: 13 puntos de historia

---

## US-009: Multi-posting Autom√°tico en Job Boards

**Como** Recruiter
**Quiero** publicar una oferta en m√∫ltiples job boards con un solo clic
**Para** maximizar el alcance sin tener que publicar manualmente en cada plataforma

### Descripci√≥n
Una vez creada una oferta, el recruiter debe poder seleccionar en qu√© job boards publicarla (LinkedIn, Indeed, Glassdoor, InfoJobs, etc.) y el sistema debe encargarse de publicarla autom√°ticamente en todas las plataformas seleccionadas, rastreando el rendimiento de cada canal.

### Criterios de Aceptaci√≥n
- [ ] Al publicar una oferta, se muestra lista de job boards disponibles (m√≠nimo 10)
- [ ] Cada job board muestra: logo, costo (si aplica), tiempo estimado de publicaci√≥n
- [ ] El recruiter puede seleccionar m√∫ltiples job boards
- [ ] El sistema adapta el formato de la oferta a los requisitos de cada plataforma
- [ ] Se muestra progreso de publicaci√≥n en cada canal
- [ ] El estado de publicaci√≥n se actualiza en tiempo real (pending, published, failed)
- [ ] Si falla en alg√∫n canal, se muestra error espec√≠fico y opci√≥n de reintentar
- [ ] Se trackea la fuente de cada aplicaci√≥n recibida
- [ ] El recruiter puede ver m√©tricas de rendimiento por canal (aplicaciones, views)
- [ ] Se puede despublicar de todos los canales con un clic

### Notas T√©cnicas
- Integration Service con conectores a APIs de job boards
- Uso de n8n o similar para workflows de integraci√≥n
- Tabla `job_posting_channel` para trackeo
- Endpoint: `POST /api/v1/jobs/{id}/publish`
- Eventos Kafka para procesamiento as√≠ncrono

### Definici√≥n de Done (DoD)
- [ ] C√≥digo implementado y revisado (code review)
- [ ] Tests unitarios escritos y pasando (>80% cobertura)
- [ ] Tests de integraci√≥n con al menos 3 job boards
- [ ] Documentaci√≥n de integraciones
- [ ] Desplegado en ambiente de staging
- [ ] Aprobaci√≥n del Product Owner

### Mockups/Wireframes
- Selector de job boards con checkboxes
- Estado de publicaci√≥n por canal
- Dashboard de m√©tricas por canal

### Dependencias
- Integration Service desplegado
- Credenciales API de job boards configuradas
- Analytics Service para m√©tricas

### Prioridad: Media
### Estimaci√≥n: 21 puntos de historia

---

## US-010: Dashboard de Analytics en Tiempo Real

**Como** Head of Talent Acquisition
**Quiero** ver un dashboard con m√©tricas clave de recruiting en tiempo real
**Para** tomar decisiones informadas y optimizar los procesos de contrataci√≥n

### Descripci√≥n
El sistema debe proporcionar un dashboard ejecutivo con KPIs de recruiting incluyendo: time-to-hire, candidatos por etapa, fuentes m√°s efectivas, ratio de conversi√≥n del pipeline, y comparativas hist√≥ricas. Las m√©tricas deben actualizarse en tiempo real.

### Criterios de Aceptaci√≥n
- [ ] El dashboard muestra m√©tricas globales y puede filtrarse por: departamento, recruiter, per√≠odo
- [ ] Se visualiza: Time-to-hire promedio (con tendencia), candidatos activos por etapa, ofertas abiertas
- [ ] Gr√°fico de funnel con ratios de conversi√≥n entre etapas
- [ ] Top 5 fuentes de candidatos por efectividad (aplicaciones ‚Üí contrataciones)
- [ ] Comparativa mes actual vs mes anterior
- [ ] Los datos se actualizan cada 5 minutos autom√°ticamente
- [ ] Se pueden exportar reportes a PDF/Excel
- [ ] El usuario puede personalizar qu√© widgets ver
- [ ] Existe versi√≥n m√≥vil responsive del dashboard
- [ ] Se pueden configurar alertas para umbrales (ej: time-to-hire > 30 d√≠as)

### Notas T√©cnicas
- Analytics Service con Apache Spark para agregaciones
- Materializaci√≥n de m√©tricas en PostgreSQL (CQRS read model)
- Frontend: Chart.js o Recharts para visualizaciones
- Endpoint: `GET /api/v1/analytics/dashboard`
- WebSocket para actualizaciones incrementales
- Export: generaci√≥n de PDF con Puppeteer

### Definici√≥n de Done (DoD)
- [ ] C√≥digo implementado y revisado (code review)
- [ ] Tests unitarios escritos y pasando (>80% cobertura)
- [ ] Performance: carga inicial < 3 segundos
- [ ] Documentaci√≥n actualizada
- [ ] Desplegado en ambiente de staging
- [ ] Aprobaci√≥n del Product Owner

### Mockups/Wireframes
- Layout del dashboard con widgets
- Gr√°ficos de funnel y tendencias
- Versi√≥n m√≥vil

### Dependencias
- Datos hist√≥ricos disponibles
- Analytics Service desplegado
- Todas las US anteriores para generar datos

### Prioridad: Baja
### Estimaci√≥n: 21 puntos de historia

---

## Resumen de User Stories

| ID | T√≠tulo | Prioridad | Estimaci√≥n |
|----|--------|-----------|------------|
| US-001 | Creaci√≥n de Ofertas con IA | Alta | 13 pts |
| US-002 | Pipeline Kanban de Candidatos | Alta | 8 pts |
| US-003 | Aplicaci√≥n y Parsing de CV con IA | Alta | 13 pts |
| US-004 | Programaci√≥n Autom√°tica de Entrevistas | Alta | 21 pts |
| US-005 | Scoring Autom√°tico de Candidatos | Alta | 21 pts |
| US-006 | Evaluaci√≥n con Scorecards | Media | 13 pts |
| US-007 | Colaboraci√≥n en Tiempo Real | Media | 21 pts |
| US-008 | Panel de Decisi√≥n Colaborativa | Media | 13 pts |
| US-009 | Multi-posting en Job Boards | Media | 21 pts |
| US-010 | Dashboard de Analytics | Baja | 21 pts |

**Total: 165 puntos de historia**

---

# Parte 2: Product Backlog - LTI ATS

## Metodolog√≠a de Priorizaci√≥n: MoSCoW + Value vs Effort Matrix

Para priorizar el backlog del producto LTI, se utiliz√≥ una combinaci√≥n de dos metodolog√≠as:

### 1. MoSCoW Method
Clasificaci√≥n de cada User Story seg√∫n su criticidad para el MVP y versiones posteriores:
- **Must Have**: Funcionalidades esenciales sin las cuales el producto no es viable
- **Should Have**: Importantes, pero el producto puede lanzarse sin ellas
- **Could Have**: Deseables si hay tiempo y recursos
- **Won't Have (this time)**: Fuera de scope para esta versi√≥n

### 2. Value vs Effort Matrix (WSJF - Weighted Shortest Job First)
Para las historias Must y Should, se aplic√≥ un an√°lisis de:
- **Business Value** (1-10): Impacto en el negocio y diferenciaci√≥n
- **User Value** (1-10): Beneficio directo para el usuario
- **Risk Reduction** (1-10): Reduce riesgo t√©cnico o de negocio
- **Effort** (puntos de historia de Fibonacci)

**WSJF Score = (Business Value + User Value + Risk Reduction) / Effort**

---

## Clasificaci√≥n MoSCoW

### üî¥ Must Have (MVP - v1.0)
| ID | User Story | Business Value | User Value | Risk Reduction | Effort | WSJF Score |
|----|------------|----------------|------------|----------------|--------|------------|
| US-003 | Aplicaci√≥n y Parsing de CV con IA | 10 | 10 | 8 | 13 | 2.15 |
| US-005 | Scoring Autom√°tico de Candidatos | 10 | 9 | 9 | 21 | 1.33 |
| US-002 | Pipeline Kanban de Candidatos | 8 | 10 | 6 | 8 | 3.00 |
| US-001 | Creaci√≥n de Ofertas con IA | 9 | 8 | 7 | 13 | 1.85 |

### üü° Should Have (v1.5)
| ID | User Story | Business Value | User Value | Risk Reduction | Effort | WSJF Score |
|----|------------|----------------|------------|----------------|--------|------------|
| US-004 | Programaci√≥n Autom√°tica de Entrevistas | 8 | 9 | 5 | 21 | 1.05 |
| US-006 | Evaluaci√≥n con Scorecards | 7 | 8 | 6 | 13 | 1.62 |
| US-007 | Colaboraci√≥n en Tiempo Real | 9 | 8 | 7 | 21 | 1.14 |

### üü¢ Could Have (v2.0)
| ID | User Story | Business Value | User Value | Risk Reduction | Effort | WSJF Score |
|----|------------|----------------|------------|----------------|--------|------------|
| US-008 | Panel de Decisi√≥n Colaborativa | 7 | 7 | 4 | 13 | 1.38 |
| US-009 | Multi-posting en Job Boards | 8 | 7 | 3 | 21 | 0.86 |

### ‚ö™ Won't Have (this release)
| ID | User Story | Raz√≥n |
|----|------------|-------|
| US-010 | Dashboard de Analytics | Requiere datos hist√≥ricos; mejor para v2.5+ |

---

## Backlog Priorizado Final

Ordenado por prioridad de implementaci√≥n (considerando dependencias t√©cnicas y WSJF):

### Sprint 1-2: Foundation
| Orden | ID | User Story | Estimaci√≥n | Justificaci√≥n |
|-------|----|-----------|-----------:|---------------|
| 1 | US-002 | Pipeline Kanban de Candidatos | 8 pts | WSJF m√°s alto (3.00), base visual del sistema, baja complejidad |
| 2 | US-001 | Creaci√≥n de Ofertas con IA | 13 pts | WSJF 1.85, necesario para tener candidatos, muestra diferenciaci√≥n IA |

### Sprint 3-4: AI Core
| Orden | ID | User Story | Estimaci√≥n | Justificaci√≥n |
|-------|----|-----------|-----------:|---------------|
| 3 | US-003 | Aplicaci√≥n y Parsing de CV con IA | 13 pts | WSJF 2.15, habilita todo el flujo de candidatos |
| 4 | US-005 | Scoring Autom√°tico de Candidatos | 21 pts | Core value proposition, depende de US-003 |

### Sprint 5-6: Productivity
| Orden | ID | User Story | Estimaci√≥n | Justificaci√≥n |
|-------|----|-----------|-----------:|---------------|
| 5 | US-006 | Evaluaci√≥n con Scorecards | 13 pts | Habilita proceso de entrevistas estructurado |
| 6 | US-004 | Programaci√≥n Autom√°tica de Entrevistas | 21 pts | Automatizaci√≥n clave, depende de US-006 |

### Sprint 7-8: Collaboration
| Orden | ID | User Story | Estimaci√≥n | Justificaci√≥n |
|-------|----|-----------|-----------:|---------------|
| 7 | US-007 | Colaboraci√≥n en Tiempo Real | 21 pts | Diferenciador vs competencia |
| 8 | US-008 | Panel de Decisi√≥n Colaborativa | 13 pts | Depende de US-007 y US-006 |

### Sprint 9-10: Scale
| Orden | ID | User Story | Estimaci√≥n | Justificaci√≥n |
|-------|----|-----------|-----------:|---------------|
| 9 | US-009 | Multi-posting en Job Boards | 21 pts | Aumenta adquisici√≥n de candidatos |
| 10 | US-010 | Dashboard de Analytics | 21 pts | Requiere datos hist√≥ricos, cierra v2.0 |

---

## Visualizaci√≥n del Backlog

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           PRODUCT BACKLOG - LTI ATS                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                             ‚îÇ
‚îÇ  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó   ‚îÇ
‚îÇ  ‚ïë MVP (v1.0) - Must Have                                    76 pts    ‚ïë   ‚îÇ
‚îÇ  ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£   ‚îÇ
‚îÇ  ‚ïë                                                                      ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ US-002         ‚îÇ  ‚îÇ US-001         ‚îÇ                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ Pipeline       ‚îÇ  ‚îÇ Ofertas IA     ‚îÇ                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ Kanban         ‚îÇ  ‚îÇ                ‚îÇ                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ 8 pts ‚≠ê‚≠ê‚≠ê    ‚îÇ  ‚îÇ 13 pts ‚≠ê‚≠ê     ‚îÇ                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë                                                                      ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ US-003         ‚îÇ  ‚îÇ US-005         ‚îÇ                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ Parsing CV     ‚îÇ  ‚îÇ AI Scoring     ‚îÇ                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ con IA         ‚îÇ  ‚îÇ                ‚îÇ                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ 13 pts ‚≠ê‚≠ê‚≠ê   ‚îÇ  ‚îÇ 21 pts ‚≠ê       ‚îÇ                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë                                                                      ‚ïë   ‚îÇ
‚îÇ  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù   ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó   ‚îÇ
‚îÇ  ‚ïë v1.5 - Should Have                                        55 pts    ‚ïë   ‚îÇ
‚îÇ  ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£   ‚îÇ
‚îÇ  ‚ïë                                                                      ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ US-006         ‚îÇ  ‚îÇ US-004         ‚îÇ  ‚îÇ US-007         ‚îÇ         ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ Scorecards     ‚îÇ  ‚îÇ Scheduling     ‚îÇ  ‚îÇ Real-time      ‚îÇ         ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ                ‚îÇ  ‚îÇ Auto           ‚îÇ  ‚îÇ Collab         ‚îÇ         ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ 13 pts         ‚îÇ  ‚îÇ 21 pts         ‚îÇ  ‚îÇ 21 pts         ‚îÇ         ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚ïë   ‚îÇ
‚îÇ  ‚ïë                                                                      ‚ïë   ‚îÇ
‚îÇ  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù   ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó   ‚îÇ
‚îÇ  ‚ïë v2.0 - Could Have                                         34 pts    ‚ïë   ‚îÇ
‚îÇ  ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£   ‚îÇ
‚îÇ  ‚ïë                                                                      ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ US-008         ‚îÇ  ‚îÇ US-009         ‚îÇ                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ Decision       ‚îÇ  ‚îÇ Multi-posting  ‚îÇ                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ Panel          ‚îÇ  ‚îÇ                ‚îÇ                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îÇ 13 pts         ‚îÇ  ‚îÇ 21 pts         ‚îÇ                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                             ‚ïë   ‚îÇ
‚îÇ  ‚ïë                                                                      ‚ïë   ‚îÇ
‚îÇ  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù   ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Icebox - Won't Have (this release)                        21 pts    ‚îÇ   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§   ‚îÇ
‚îÇ  ‚îÇ  US-010: Dashboard de Analytics                                      ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Dependencias entre User Stories

```mermaid
graph TD
    subgraph MVP ["MVP (v1.0)"]
        US001[US-001<br/>Ofertas con IA]
        US002[US-002<br/>Pipeline Kanban]
        US003[US-003<br/>Parsing CV IA]
        US005[US-005<br/>AI Scoring]
    end

    subgraph V15 ["v1.5"]
        US004[US-004<br/>Scheduling Auto]
        US006[US-006<br/>Scorecards]
        US007[US-007<br/>Real-time Collab]
    end

    subgraph V20 ["v2.0"]
        US008[US-008<br/>Decision Panel]
        US009[US-009<br/>Multi-posting]
    end

    subgraph Future ["v2.5+"]
        US010[US-010<br/>Analytics Dashboard]
    end

    US001 --> US003
    US003 --> US005
    US005 --> US002
    US002 --> US006
    US006 --> US004
    US002 --> US007
    US007 --> US008
    US006 --> US008
    US001 --> US009

    US002 --> US010
    US005 --> US010
    US009 --> US010

    classDef mvp fill:#ffcdd2,stroke:#b71c1c
    classDef v15 fill:#fff9c4,stroke:#f57f17
    classDef v20 fill:#c8e6c9,stroke:#2e7d32
    classDef future fill:#e0e0e0,stroke:#616161

    class US001,US002,US003,US005 mvp
    class US004,US006,US007 v15
    class US008,US009 v20
    class US010 future
```

---

## M√©tricas de Velocidad Estimadas

Asumiendo un equipo de 5 desarrolladores con velocidad promedio de 40 puntos/sprint (sprints de 2 semanas):

| Release | User Stories | Puntos Totales | Sprints Estimados |
|---------|-------------|---------------:|------------------:|
| MVP (v1.0) | US-002, US-001, US-003, US-005 | 55 pts | 2 sprints |
| v1.5 | US-006, US-004, US-007 | 55 pts | 2 sprints |
| v2.0 | US-008, US-009 | 34 pts | 1 sprint |
| v2.5 | US-010 | 21 pts | 1 sprint |

**Total estimado: 6 sprints (12 semanas) para completar todas las User Stories**

---

## Criterios de Re-priorizaci√≥n

El backlog debe revisarse cada sprint considerando:

1. **Feedback de usuarios beta** (a partir de MVP)
2. **M√©tricas de uso** de features implementadas
3. **Cambios en el mercado** o competencia
4. **Disponibilidad de integraciones** (APIs de terceros)
5. **Deuda t√©cnica** acumulada

---

## Notas de Release

### MVP (v1.0) - "Foundation"
- **Objetivo**: Producto funcional para early adopters
- **Usuarios target**: 5-10 empresas piloto
- **Key feature**: AI Scoring como diferenciador

### v1.5 - "Productivity"
- **Objetivo**: Automatizaci√≥n del proceso de entrevistas
- **Usuarios target**: 50 empresas
- **Key feature**: Scheduling autom√°tico

### v2.0 - "Collaboration"
- **Objetivo**: Colaboraci√≥n en tiempo real diferenciadora
- **Usuarios target**: 200 empresas
- **Key feature**: Real-time collaboration estilo Figma

---

# Parte 3: Experimento de Prompts para Generaci√≥n de Backlog

Este documento detalla los diferentes prompts utilizados para generar el Product Backlog de LTI a partir de la documentaci√≥n de dise√±o, junto con el an√°lisis de resultados y conclusiones.

---

## Prompt 1: Enfoque Directo Simple

```
Bas√°ndote en el documento de dise√±o de LTI (un ATS con IA), genera un Product Backlog
con las User Stories priorizadas.
```

### Resultado
- Gener√≥ una lista b√°sica de funcionalidades sin formato de User Story
- No incluy√≥ criterios de aceptaci√≥n
- Priorizaci√≥n vaga ("Alta", "Media", "Baja") sin metodolog√≠a
- Sin estimaciones
- Sin dependencias entre historias

### Evaluaci√≥n: ‚≠ê (1/5)
**Problema**: Demasiado gen√©rico, no aprovecha el contexto del documento de dise√±o.

---

## Prompt 2: Enfoque con Rol + Estructura Expl√≠cita

```
Act√∫a como Product Owner de un equipo Scrum. Bas√°ndote en el siguiente documento de
dise√±o de un ATS llamado LTI, genera User Stories para un Product Backlog.

Para cada User Story incluye:
- T√≠tulo descriptivo
- Formato "Como [rol] quiero [funcionalidad] para [beneficio]"
- Criterios de aceptaci√≥n (al menos 5)
- Estimaci√≥n en puntos de historia
- Prioridad

Genera al menos 10 User Stories.

[Pegar documento de dise√±o]
```

### Resultado
- Formato correcto de User Stories
- Criterios de aceptaci√≥n b√°sicos pero funcionales
- Estimaciones presentes pero sin justificaci√≥n
- Priorizaci√≥n sin metodolog√≠a clara
- No consider√≥ dependencias t√©cnicas
- No relacion√≥ las historias con el roadmap del documento

### Evaluaci√≥n: ‚≠ê‚≠ê‚≠ê (3/5)
**Mejora**: La estructura expl√≠cita mejor√≥ significativamente el output.
**Problema**: Falta conexi√≥n con la arquitectura t√©cnica del documento.

---

## Prompt 3: Enfoque Multi-paso con Contexto T√©cnico

```
Eres un Product Owner senior con experiencia en productos HR Tech. Vas a generar
el Product Backlog para LTI, un ATS de nueva generaci√≥n.

PASO 1: Primero, analiza el documento de dise√±o adjunto identificando:
- Casos de uso principales
- Componentes t√©cnicos clave (AI Service, Collaboration Service, etc.)
- Roadmap propuesto (MVP, v1.5, v2.0)
- Actores del sistema

PASO 2: Para cada funcionalidad identificada, crea una User Story siguiendo
esta plantilla exacta:

---
## US-XXX: [T√≠tulo]

**Como** [rol del sistema: Recruiter/Hiring Manager/Candidato/Admin]
**Quiero** [funcionalidad espec√≠fica]
**Para** [beneficio medible]

### Descripci√≥n
[2-3 p√°rrafos de contexto]

### Criterios de Aceptaci√≥n
- [ ] [Criterio espec√≠fico y verificable]
(m√≠nimo 8 criterios)

### Notas T√©cnicas
[Referencias a componentes del documento: AI Service, tablas DB, endpoints]

### Dependencias
[Otras US necesarias]

### Prioridad: [Alta/Media/Baja]
### Estimaci√≥n: [Fibonacci: 1,2,3,5,8,13,21] puntos
---

PASO 3: Organiza las User Stories en un backlog priorizado usando la metodolog√≠a
MoSCoW, justificando cada clasificaci√≥n.

[Documento de dise√±o adjunto]
```

### Resultado
- Excelente estructura y formato
- User Stories alineadas con el roadmap del documento
- Referencias t√©cnicas precisas (tablas, servicios, endpoints)
- Dependencias bien identificadas
- MoSCoW aplicado correctamente
- Conexi√≥n clara entre US y arquitectura

### Evaluaci√≥n: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)
**√âxito**: El enfoque multi-paso forz√≥ an√°lisis previo antes de generar contenido.

---

## Prompt 4: Enfoque con WSJF + Matrix

```
Como Product Owner, genera un backlog priorizado para LTI ATS usando la metodolog√≠a
WSJF (Weighted Shortest Job First).

Para cada User Story calcula:
- Business Value (1-10)
- User Value (1-10)
- Risk Reduction (1-10)
- Effort (puntos de historia)
- WSJF Score = (BV + UV + RR) / Effort

Presenta el backlog ordenado por WSJF Score descendente.

[Documento de dise√±o]
```

### Resultado
- Priorizaci√≥n matem√°ticamente s√≥lida
- Justificaciones claras para cada valor
- F√°cil de explicar a stakeholders
- Sin embargo, falt√≥ contexto de User Stories completas
- Se enfoc√≥ demasiado en la priorizaci√≥n y poco en el contenido

### Evaluaci√≥n: ‚≠ê‚≠ê‚≠ê‚≠ê (4/5)
**Fortaleza**: Metodolog√≠a de priorizaci√≥n robusta.
**Debilidad**: User Stories menos detalladas.

---

## Prompt 5 (GANADOR): Enfoque Combinado

```
Eres un Product Owner senior con 10 a√±os de experiencia en HR Tech, espec√≠ficamente
en ATS (Applicant Tracking Systems). Tu tarea es crear la documentaci√≥n completa
de Product Backlog para LTI.

CONTEXTO:
- LTI es un ATS de nueva generaci√≥n con IA integrada
- Compite con Greenhouse, Lever, Workable
- Diferenciadores: IA nativa, colaboraci√≥n real-time, UX moderna
- Arquitectura: microservicios, event-driven, multi-tenant

ENTREGABLES REQUERIDOS:

1. USER STORIES (m√≠nimo 10)
   Usa esta plantilla para CADA historia:

   ## US-XXX: [T√≠tulo descriptivo]

   **Como** [Recruiter | Hiring Manager | Candidato | Admin]
   **Quiero** [acci√≥n espec√≠fica]
   **Para** [beneficio cuantificable cuando sea posible]

   ### Descripci√≥n
   [Contexto de 2-3 p√°rrafos explicando el problema y la soluci√≥n]

   ### Criterios de Aceptaci√≥n
   - [ ] [Criterio 1 - espec√≠fico, medible, verificable]
   - [ ] [Criterio 2]
   ... (m√≠nimo 8, m√°ximo 12)

   ### Notas T√©cnicas
   - Servicio responsable: [Job Service | AI Service | etc.]
   - Tablas afectadas: [nombre de tablas del modelo de datos]
   - Endpoints: [m√©todo + ruta]
   - Eventos: [eventos Kafka si aplica]

   ### Definici√≥n de Done
   - [ ] Code review aprobado
   - [ ] Tests >80% cobertura
   - [ ] Documentaci√≥n actualizada
   - [ ] Deploy en staging
   - [ ] PO sign-off

   ### Dependencias
   [Lista de US-XXX que deben completarse antes]

   ### Prioridad: [Alta | Media | Baja]
   ### Estimaci√≥n: [Fibonacci] puntos de historia

2. BACKLOG PRIORIZADO
   - Aplica metodolog√≠a MoSCoW (Must/Should/Could/Won't)
   - Dentro de cada categor√≠a, ordena por WSJF
   - Incluye tabla con: Business Value, User Value, Risk Reduction, Effort, WSJF
   - Agrupa por releases seg√∫n el roadmap del documento (MVP, v1.5, v2.0)

3. VISUALIZACI√ìN
   - Diagrama ASCII del backlog
   - Diagrama mermaid de dependencias entre US

4. M√âTRICAS
   - Estimaci√≥n de velocidad del equipo
   - Proyecci√≥n de sprints por release

DOCUMENTO DE DISE√ëO A ANALIZAR:
[Contenido completo del documento LTI-JVP.md]
```

### Resultado
- Documentaci√≥n completa y profesional
- User Stories con todos los campos necesarios
- Conexi√≥n directa con arquitectura t√©cnica del documento
- Metodolog√≠a de priorizaci√≥n h√≠brida (MoSCoW + WSJF)
- Visualizaciones √∫tiles
- M√©tricas de planificaci√≥n incluidas
- Dependencias claras con diagrama mermaid

### Evaluaci√≥n: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)
**Mejor resultado global**

---

## An√°lisis Comparativo

| Aspecto | P1 | P2 | P3 | P4 | P5 |
|---------|----|----|----|----|-----|
| Formato User Stories | ‚ùå | ‚úÖ | ‚úÖ | üü° | ‚úÖ |
| Criterios de Aceptaci√≥n | ‚ùå | üü° | ‚úÖ | ‚ùå | ‚úÖ |
| Notas T√©cnicas | ‚ùå | ‚ùå | ‚úÖ | ‚ùå | ‚úÖ |
| Dependencias | ‚ùå | ‚ùå | ‚úÖ | ‚ùå | ‚úÖ |
| Metodolog√≠a Priorizaci√≥n | ‚ùå | ‚ùå | ‚úÖ | ‚úÖ | ‚úÖ |
| Visualizaci√≥n | ‚ùå | ‚ùå | üü° | ‚ùå | ‚úÖ |
| Conexi√≥n con Roadmap | ‚ùå | ‚ùå | ‚úÖ | üü° | ‚úÖ |
| Estimaciones Justificadas | ‚ùå | ‚ùå | üü° | ‚úÖ | ‚úÖ |

**Leyenda**: ‚úÖ Cumple | üü° Parcial | ‚ùå No cumple

---

## Conclusiones

### ¬øPor qu√© el Prompt 5 fue el m√°s efectivo?

1. **Contexto Rico**: Establecer el contexto de HR Tech y competencia ayud√≥ a generar contenido m√°s relevante y realista.

2. **Rol Espec√≠fico con Experiencia**: "Product Owner senior con 10 a√±os de experiencia" produce respuestas m√°s maduras que simplemente "Product Owner".

3. **Estructura de Plantilla Expl√≠cita**: Proporcionar la plantilla exacta con todos los campos elimina la ambig√ºedad sobre qu√© incluir.

4. **Entregables Numerados**: Dividir la solicitud en entregables claros (1. User Stories, 2. Backlog, 3. Visualizaci√≥n, 4. M√©tricas) asegura que ning√∫n aspecto se omita.

5. **Metodolog√≠a Especificada**: Indicar expl√≠citamente MoSCoW + WSJF evita priorizaciones arbitrarias.

6. **Conexi√≥n con Documento**: Mencionar que el output debe conectarse con la arquitectura (servicios, tablas, endpoints) del documento fuente produce resultados t√©cnicamente s√≥lidos.

7. **Ejemplos de Valores**: Proporcionar rangos (ej: "Business Value 1-10", "Fibonacci para estimaciones") estandariza el output.

### Patrones Identificados para Prompts Efectivos de Backlog

```
ESTRUCTURA DE PROMPT EFECTIVO:

1. IDENTIDAD
   "Eres [rol espec√≠fico] con [a√±os experiencia] en [dominio]"

2. CONTEXTO
   - Qu√© es el producto
   - Competencia
   - Diferenciadores
   - Restricciones t√©cnicas

3. ENTREGABLES (numerados)
   - User Stories (con plantilla completa)
   - Priorizaci√≥n (metodolog√≠a espec√≠fica)
   - Visualizaci√≥n (formatos espec√≠ficos)
   - M√©tricas adicionales

4. PLANTILLAS
   - Proporcionar plantilla exacta para cada entregable
   - Incluir campos obligatorios y opcionales

5. DOCUMENTO FUENTE
   - Anexar el documento de dise√±o completo
   - Mencionar qu√© elementos del documento deben referenciarse
```

### Recomendaciones para Futuros Prompts

1. **Siempre proporcionar plantilla expl√≠cita** - Reduce variabilidad en el output
2. **Especificar metodolog√≠a de priorizaci√≥n** - Evita priorizaciones arbitrarias
3. **Incluir contexto de dominio** - Mejora la relevancia del contenido
4. **Solicitar m√∫ltiples formatos de visualizaci√≥n** - ASCII, Mermaid, tablas
5. **Pedir conexi√≥n expl√≠cita con arquitectura** - Produce US t√©cnicamente viables
6. **Dividir en entregables numerados** - Asegura completitud

---

## Aplicaci√≥n al Proyecto LTI

El backlog generado para LTI utilizando el Prompt 5 result√≥ en:

- **10 User Stories** completas y t√©cnicamente viables
- **Priorizaci√≥n MoSCoW + WSJF** con justificaciones
- **Mapa de dependencias** que evita bloqueos en desarrollo
- **Proyecci√≥n de sprints** para planificaci√≥n de recursos
- **Conexi√≥n directa** con la arquitectura de microservicios propuesta

Este enfoque permitir√° al equipo de desarrollo comenzar la implementaci√≥n con claridad sobre el orden de trabajo y las interdependencias t√©cnicas.

---

# Parte 4: Tickets de Trabajo - US-005: Scoring Autom√°tico de Candidatos con IA

## User Story de Referencia

**US-005: Scoring Autom√°tico de Candidatos con IA**

**Como** Recruiter
**Quiero** que el sistema calcule autom√°ticamente un score de match para cada candidato
**Para** priorizar mi tiempo en los candidatos m√°s relevantes para el puesto

---

## Desglose T√©cnico

La implementaci√≥n de esta User Story se divide en los siguientes tickets de trabajo, organizados por componentes de la arquitectura.

---

## EPIC: AI Scoring System

### Tickets Backend - AI Service

---

### TK-001: Dise√±o e Implementaci√≥n del Modelo de Datos para AI Score

**Tipo**: Backend
**Componente**: Database / AI Service
**Prioridad**: Alta (Blocker)

#### Descripci√≥n
Crear las estructuras de base de datos necesarias para almacenar los scores calculados por IA, incluyendo el score general, desglose por categor√≠as y metadatos del c√°lculo.

#### Tareas T√©cnicas
- [ ] Crear migraci√≥n para tabla `ai_score` en PostgreSQL:
  ```sql
  CREATE TABLE ai_score (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    application_id UUID NOT NULL REFERENCES application(id) ON DELETE CASCADE,
    overall_score DECIMAL(5,2) NOT NULL CHECK (overall_score >= 0 AND overall_score <= 100),
    skill_matches JSONB NOT NULL DEFAULT '{}',
    experience_match JSONB NOT NULL DEFAULT '{}',
    education_match JSONB NOT NULL DEFAULT '{}',
    cultural_fit JSONB NOT NULL DEFAULT '{}',
    summary TEXT,
    confidence DECIMAL(3,2) CHECK (confidence >= 0 AND confidence <= 1),
    model_version VARCHAR(50) NOT NULL,
    calculated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    calculation_time_ms INTEGER,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(application_id)
  );
  ```
- [ ] Crear √≠ndices para optimizar consultas:
  ```sql
  CREATE INDEX idx_ai_score_application ON ai_score(application_id);
  CREATE INDEX idx_ai_score_overall ON ai_score(overall_score DESC);
  CREATE INDEX idx_ai_score_calculated ON ai_score(calculated_at);
  ```
- [ ] Crear modelo SQLAlchemy/Pydantic en Python
- [ ] Implementar repository pattern para operaciones CRUD
- [ ] Escribir tests unitarios para el repository

#### Criterios de Aceptaci√≥n
- [ ] Migraci√≥n ejecuta sin errores en ambiente de desarrollo y staging
- [ ] El modelo Pydantic valida correctamente todos los campos
- [ ] Tests unitarios pasan con >90% cobertura
- [ ] √çndices mejoran performance de consultas (benchmark documentado)

#### Definici√≥n de Done
- [ ] PR aprobado por 2 revisores
- [ ] Migraci√≥n aplicada en staging
- [ ] Documentaci√≥n de schema actualizada
- [ ] Tests pasando en CI

#### Estimaci√≥n: 3 puntos de historia (Fibonacci)
#### Estimaci√≥n en horas: 6-8 horas

---

### TK-002: Implementaci√≥n del SkillMatcher Component

**Tipo**: Backend
**Componente**: AI Service - Candidate Scorer
**Prioridad**: Alta

#### Descripci√≥n
Implementar el componente `SkillMatcher` que extrae skills del CV del candidato y calcula el porcentaje de match con los requisitos del puesto usando embeddings sem√°nticos.

#### Tareas T√©cnicas
- [ ] Crear clase `SkillMatcher` en `ai_service/components/skill_matcher.py`:
  ```python
  class SkillMatcher:
      def __init__(self, embedding_generator: EmbeddingGenerator):
          self.embedder = embedding_generator

      async def extract_skills(self, text: str) -> List[Skill]
      async def match_skills(
          self,
          candidate_skills: List[Skill],
          required_skills: List[Skill]
      ) -> SkillMatch
      def calculate_similarity(self, skill1: Skill, skill2: Skill) -> float
  ```
- [ ] Implementar extracci√≥n de skills usando spaCy NER + LLM fallback
- [ ] Implementar matching sem√°ntico usando cosine similarity de embeddings
- [ ] Crear dataclasses para `Skill`, `SkillPair`, `SkillMatch`
- [ ] Implementar cache de embeddings de skills comunes
- [ ] Manejar sin√≥nimos y variaciones (ej: "JS" = "JavaScript")
- [ ] Escribir tests unitarios con casos edge (skills ambiguos, idiomas mixtos)

#### Criterios de Aceptaci√≥n
- [ ] Extrae correctamente skills t√©cnicas de CVs en ingl√©s y espa√±ol
- [ ] Similarity threshold configurable (default 0.75)
- [ ] Tiempo de procesamiento < 2 segundos por CV
- [ ] Maneja gracefully CVs sin skills identificables
- [ ] Tests con fixtures de CVs reales (anonimizados)

#### Definici√≥n de Done
- [ ] PR aprobado
- [ ] Tests unitarios >85% cobertura
- [ ] Documentaci√≥n de API interna
- [ ] Logging estructurado implementado

#### Dependencias
- TK-001: Modelo de datos
- EmbeddingGenerator existente

#### Estimaci√≥n: 8 puntos de historia
#### Estimaci√≥n en horas: 16-20 horas

---

### TK-003: Implementaci√≥n del ExperienceMatcher Component

**Tipo**: Backend
**Componente**: AI Service - Candidate Scorer
**Prioridad**: Alta

#### Descripci√≥n
Implementar el componente `ExperienceMatcher` que analiza la experiencia laboral del candidato y calcula el grado de match con los requisitos de experiencia del puesto.

#### Tareas T√©cnicas
- [ ] Crear clase `ExperienceMatcher` en `ai_service/components/experience_matcher.py`:
  ```python
  class ExperienceMatcher:
      def __init__(self, llm_client: LLMClient):
          self.llm = llm_client

      async def analyze_experience(
          self,
          cv_text: str,
          requirements: str
      ) -> ExperienceMatch

      def calculate_years_match(
          self,
          candidate_years: int,
          required_years: int
      ) -> float

      async def analyze_industry_relevance(
          self,
          experiences: List[Experience],
          target_industry: str
      ) -> float
  ```
- [ ] Implementar extracci√≥n de a√±os de experiencia con regex + LLM validation
- [ ] Crear scoring de progresi√≥n de carrera (junior‚Üísenior)
- [ ] Implementar an√°lisis de relevancia de industria
- [ ] Crear prompt template para an√°lisis de LLM
- [ ] Implementar fallback para CVs con formato no est√°ndar
- [ ] Escribir tests unitarios y de integraci√≥n

#### Criterios de Aceptaci√≥n
- [ ] Extrae a√±os de experiencia con precisi√≥n >90% en test set
- [ ] Identifica correctamente niveles de seniority
- [ ] Reconoce industrias relevantes vs no relevantes
- [ ] Funciona con experiencias en m√∫ltiples idiomas
- [ ] Tiempo de procesamiento < 3 segundos

#### Definici√≥n de Done
- [ ] PR aprobado
- [ ] Tests unitarios >85% cobertura
- [ ] Prompt templates versionados en Prompt Manager
- [ ] M√©tricas de precisi√≥n documentadas

#### Dependencias
- TK-001: Modelo de datos
- LLMClient existente

#### Estimaci√≥n: 8 puntos de historia
#### Estimaci√≥n en horas: 16-20 horas

---

### TK-004: Implementaci√≥n del CulturalFitAnalyzer Component

**Tipo**: Backend
**Componente**: AI Service - Candidate Scorer
**Prioridad**: Media

#### Descripci√≥n
Implementar el componente `CulturalFitAnalyzer` que analiza indicadores de fit cultural del candidato bas√°ndose en el contenido del CV, carta de presentaci√≥n (si existe), y los valores declarados de la organizaci√≥n.

#### Tareas T√©cnicas
- [ ] Crear clase `CulturalFitAnalyzer` en `ai_service/components/cultural_fit.py`:
  ```python
  class CulturalFitAnalyzer:
      def __init__(self, llm_client: LLMClient, prompt_manager: PromptManager):
          self.llm = llm_client
          self.prompts = prompt_manager

      async def analyze_fit(
          self,
          candidate_profile: CandidateProfile,
          org_values: List[str]
      ) -> CulturalFit

      def extract_indicators(self, text: str) -> List[CulturalIndicator]

      def score_alignment(
          self,
          indicators: List[CulturalIndicator],
          values: List[str]
      ) -> float
  ```
- [ ] Definir lista de indicadores culturales est√°ndar:
  - Trabajo en equipo vs trabajo individual
  - Innovaci√≥n vs estabilidad
  - Ritmo de trabajo
  - Estilo de comunicaci√≥n
- [ ] Crear prompts para extracci√≥n de indicadores con LLM
- [ ] Implementar scoring de alineaci√≥n valores-indicadores
- [ ] Manejar ausencia de informaci√≥n (score neutral, no penalizar)
- [ ] Escribir tests con casos diversos

#### Criterios de Aceptaci√≥n
- [ ] Extrae al menos 3 indicadores relevantes de CVs t√≠picos
- [ ] No produce false positives/negatives con CVs neutrales
- [ ] Score se mantiene en rango 0-100 incluso con datos incompletos
- [ ] Genera explicaci√≥n legible de concerns/positive indicators
- [ ] Tiempo de procesamiento < 4 segundos

#### Definici√≥n de Done
- [ ] PR aprobado
- [ ] Tests unitarios >80% cobertura
- [ ] Prompts revisados por equipo de Producto (evitar bias)
- [ ] Documentaci√≥n de limitaciones del an√°lisis

#### Dependencias
- TK-001: Modelo de datos
- LLMClient y PromptManager existentes

#### Estimaci√≥n: 5 puntos de historia
#### Estimaci√≥n en horas: 10-12 horas

---

### TK-005: Implementaci√≥n del CandidateScorer Orchestrator

**Tipo**: Backend
**Componente**: AI Service - Candidate Scorer
**Prioridad**: Alta

#### Descripci√≥n
Implementar el orquestador principal `CandidateScorer` que coordina todos los componentes de scoring, calcula el score final ponderado, y genera el resumen ejecutivo del candidato.

#### Tareas T√©cnicas
- [ ] Crear clase `CandidateScorer` en `ai_service/components/candidate_scorer.py`:
  ```python
  class CandidateScorer:
      def __init__(
          self,
          skill_matcher: SkillMatcher,
          experience_matcher: ExperienceMatcher,
          cultural_fit_analyzer: CulturalFitAnalyzer,
          config: ScoringConfig
      ):
          ...

      async def calculate_score(
          self,
          application: Application
      ) -> AIScore

      async def batch_score(
          self,
          applications: List[Application]
      ) -> List[AIScore]

      def generate_summary(
          self,
          scores: ScoreComponents
      ) -> str
  ```
- [ ] Implementar ponderaci√≥n configurable:
  ```python
  DEFAULT_WEIGHTS = {
      "skills": 0.40,
      "experience": 0.35,
      "cultural_fit": 0.15,
      "education": 0.10
  }
  ```
- [ ] Implementar c√°lculo de score overall:
  ```python
  overall = sum(score * weight for score, weight in zip(scores, weights))
  ```
- [ ] Implementar generaci√≥n de summary con LLM
- [ ] Implementar batch processing con concurrencia controlada
- [ ] Agregar m√©tricas de tiempo de procesamiento
- [ ] Implementar retry logic para failures transitorios
- [ ] Escribir tests de integraci√≥n end-to-end

#### Criterios de Aceptaci√≥n
- [ ] Score final es promedio ponderado de componentes
- [ ] Pesos son configurables por organizaci√≥n
- [ ] Batch de 100 candidatos procesa en < 5 minutos
- [ ] Genera summary de 2-3 oraciones coherentes
- [ ] Handles gracefully errores en componentes individuales
- [ ] Registra confidence score basado en calidad de datos

#### Definici√≥n de Done
- [ ] PR aprobado
- [ ] Tests de integraci√≥n pasando
- [ ] Performance benchmarks documentados
- [ ] Retry policy documentada

#### Dependencias
- TK-002: SkillMatcher
- TK-003: ExperienceMatcher
- TK-004: CulturalFitAnalyzer

#### Estimaci√≥n: 8 puntos de historia
#### Estimaci√≥n en horas: 16-20 horas

---

### TK-006: API REST para Scoring

**Tipo**: Backend
**Componente**: AI Service - API Controller
**Prioridad**: Alta

#### Descripci√≥n
Implementar los endpoints REST para solicitar c√°lculo de score, consultar scores existentes, y proporcionar feedback sobre la precisi√≥n.

#### Tareas T√©cnicas
- [ ] Crear endpoints en FastAPI:
  ```python
  @router.post("/applications/{application_id}/score")
  async def calculate_score(application_id: UUID) -> AIScoreResponse

  @router.get("/applications/{application_id}/score")
  async def get_score(application_id: UUID) -> AIScoreResponse

  @router.post("/applications/{application_id}/score/feedback")
  async def submit_feedback(
      application_id: UUID,
      feedback: ScoreFeedback
  ) -> FeedbackResponse

  @router.post("/jobs/{job_id}/batch-score")
  async def batch_score_job(job_id: UUID) -> BatchScoreResponse
  ```
- [ ] Implementar validaci√≥n de permisos (user debe tener acceso a la application)
- [ ] Implementar rate limiting para endpoints de scoring
- [ ] Agregar OpenAPI documentation
- [ ] Implementar response caching para GET score
- [ ] Escribir tests de API

#### Criterios de Aceptaci√≥n
- [ ] Endpoints documentados en OpenAPI/Swagger
- [ ] Autenticaci√≥n JWT validada
- [ ] Rate limit: 10 scores/minuto por usuario
- [ ] Response time < 500ms para GET cached
- [ ] Batch endpoint acepta max 100 applications

#### Definici√≥n de Done
- [ ] PR aprobado
- [ ] Tests de API >90% cobertura
- [ ] Documentaci√≥n OpenAPI actualizada
- [ ] Rate limiting configurado en Kong

#### Dependencias
- TK-005: CandidateScorer
- Auth Service (existente)

#### Estimaci√≥n: 5 puntos de historia
#### Estimaci√≥n en horas: 10-12 horas

---

### TK-007: Event Consumer para Scoring Autom√°tico

**Tipo**: Backend
**Componente**: AI Service - Event Consumer
**Prioridad**: Alta

#### Descripci√≥n
Implementar el consumer de Kafka que escucha eventos de nuevas aplicaciones (cv.uploaded) y dispara autom√°ticamente el c√°lculo de score.

#### Tareas T√©cnicas
- [ ] Crear consumer de Kafka en `ai_service/consumers/scoring_consumer.py`:
  ```python
  class ScoringConsumer:
      def __init__(self, scorer: CandidateScorer):
          self.scorer = scorer

      async def handle_cv_uploaded(self, event: CVUploadedEvent):
          # Calcular score autom√°ticamente
          score = await self.scorer.calculate_score(event.application_id)
          # Publicar resultado
          await self.publish_score_calculated(score)

      async def publish_score_calculated(self, score: AIScore):
          # Evento score.calculated para otros servicios
          ...
  ```
- [ ] Configurar consumer group y partitioning
- [ ] Implementar dead-letter queue para eventos fallidos
- [ ] Agregar retry policy exponencial
- [ ] Implementar idempotency check (no re-procesar mismo application_id)
- [ ] Agregar m√©tricas de procesamiento (lag, throughput, errors)
- [ ] Escribir tests de integraci√≥n con Kafka

#### Criterios de Aceptaci√≥n
- [ ] Consumer procesa eventos en < 30 segundos tras publicaci√≥n
- [ ] No hay p√©rdida de eventos (at-least-once delivery)
- [ ] Eventos duplicados son detectados y ignorados
- [ ] Dead-letter queue funcional para debugging
- [ ] M√©tricas visibles en Prometheus/Grafana

#### Definici√≥n de Done
- [ ] PR aprobado
- [ ] Tests de integraci√≥n pasando
- [ ] Consumer desplegado en staging
- [ ] Alertas configuradas para consumer lag

#### Dependencias
- TK-005: CandidateScorer
- Kafka infrastructure (existente)

#### Estimaci√≥n: 5 puntos de historia
#### Estimaci√≥n en horas: 10-12 horas

---

### Tickets Frontend

---

### TK-008: Componente de Visualizaci√≥n de Score

**Tipo**: Frontend
**Componente**: Web App - React
**Prioridad**: Alta

#### Descripci√≥n
Implementar el componente React que muestra el AI Score en el perfil del candidato, incluyendo el score general, el desglose por categor√≠as, y el resumen ejecutivo.

#### Tareas T√©cnicas
- [ ] Crear componente `AIScoreCard` en `components/candidates/AIScoreCard.tsx`:
  ```tsx
  interface AIScoreCardProps {
    score: AIScore;
    isLoading: boolean;
    onRefresh: () => void;
  }

  export const AIScoreCard: React.FC<AIScoreCardProps> = ({...}) => {
    // Score circular gauge
    // Category breakdown bars
    // Summary text
    // Refresh button
  }
  ```
- [ ] Implementar gauge circular para score overall (0-100)
- [ ] Implementar c√≥digo de colores:
  - Verde: >70
  - Amarillo: 40-70
  - Rojo: <40
- [ ] Crear barras de progreso para cada categor√≠a (Skills, Experience, Cultural Fit)
- [ ] Implementar tooltip con detalles al hover sobre cada categor√≠a
- [ ] Crear skeleton loader para estado de carga
- [ ] Implementar estado de error con retry
- [ ] Escribir tests unitarios con React Testing Library

#### Criterios de Aceptaci√≥n
- [ ] Score se muestra correctamente en rangos 0-100
- [ ] Colores corresponden a rangos definidos
- [ ] Tooltips muestran informaci√≥n adicional
- [ ] Loading state visible durante c√°lculo
- [ ] Componente es accesible (a11y compliant)
- [ ] Responsive en mobile y desktop

#### Definici√≥n de Done
- [ ] PR aprobado
- [ ] Tests unitarios >80% cobertura
- [ ] Storybook stories creadas
- [ ] Revisi√≥n de UX/Design aprobada

#### Dependencias
- TK-006: API endpoints disponibles
- Design system existente

#### Estimaci√≥n: 5 puntos de historia
#### Estimaci√≥n en horas: 10-12 horas

---

### TK-009: Componente de Desglose de Skills Match

**Tipo**: Frontend
**Componente**: Web App - React
**Prioridad**: Media

#### Descripci√≥n
Implementar el componente expandible que muestra el detalle del match de skills, incluyendo skills coincidentes, skills faltantes, y skills adicionales del candidato.

#### Tareas T√©cnicas
- [ ] Crear componente `SkillsMatchDetail` en `components/candidates/SkillsMatchDetail.tsx`:
  ```tsx
  interface SkillsMatchDetailProps {
    skillMatch: SkillMatch;
    isExpanded: boolean;
    onToggle: () => void;
  }
  ```
- [ ] Implementar lista de skills con iconos:
  - ‚úÖ Skill coincidente
  - ‚ùå Skill faltante (requerido)
  - ‚ûï Skill adicional (bonus)
- [ ] Mostrar porcentaje de match por skill (si hay partial match)
- [ ] Implementar collapse/expand animation
- [ ] Agregar search/filter dentro del listado de skills
- [ ] Escribir tests unitarios

#### Criterios de Aceptaci√≥n
- [ ] Skills se categorizan correctamente
- [ ] Iconograf√≠a clara y consistente
- [ ] Filter funciona en tiempo real
- [ ] Animaci√≥n de expand es fluida
- [ ] Lista scrollable si hay muchos skills

#### Definici√≥n de Done
- [ ] PR aprobado
- [ ] Tests unitarios pasando
- [ ] Storybook stories
- [ ] Aprobaci√≥n de dise√±o

#### Dependencias
- TK-008: AIScoreCard (se integra aqu√≠)

#### Estimaci√≥n: 3 puntos de historia
#### Estimaci√≥n en horas: 6-8 horas

---

### TK-010: Integraci√≥n de Score en Pipeline Kanban

**Tipo**: Frontend
**Componente**: Web App - React
**Prioridad**: Alta

#### Descripci√≥n
Integrar la visualizaci√≥n del AI Score en las tarjetas de candidatos del Pipeline Kanban, permitiendo ordenar candidatos por score y filtrar por rangos.

#### Tareas T√©cnicas
- [ ] Modificar componente `CandidateCard` para incluir score badge:
  ```tsx
  // En CandidateCard.tsx
  <ScoreBadge score={candidate.aiScore} size="sm" />
  ```
- [ ] Implementar sorting por score en columnas del Kanban:
  ```tsx
  const sortedCandidates = useMemo(() =>
    candidates.sort((a, b) => b.aiScore - a.aiScore),
    [candidates, sortBy]
  );
  ```
- [ ] Implementar filtro por rango de score:
  - Slider de rango (min-max)
  - Quick filters: "Top 25%", "Above Average", "All"
- [ ] Actualizar score en tiempo real via WebSocket cuando se recalcula
- [ ] Escribir tests de integraci√≥n

#### Criterios de Aceptaci√≥n
- [ ] Score visible en cada tarjeta de candidato
- [ ] Sorting por score funciona correctamente
- [ ] Filtros de rango funcionan en tiempo real
- [ ] WebSocket actualiza scores sin refresh
- [ ] Performance: <100ms para re-render con 100 candidatos

#### Definici√≥n de Done
- [ ] PR aprobado
- [ ] Tests de integraci√≥n pasando
- [ ] No regresi√≥n en performance del Kanban

#### Dependencias
- TK-008: Componente AIScoreCard
- US-002: Pipeline Kanban implementado

#### Estimaci√≥n: 5 puntos de historia
#### Estimaci√≥n en horas: 10-12 horas

---

### TK-011: Componente de Feedback de Score

**Tipo**: Frontend
**Componente**: Web App - React
**Prioridad**: Media

#### Descripci√≥n
Implementar el mecanismo para que recruiters proporcionen feedback sobre la precisi√≥n del score (thumbs up/down), permitiendo mejorar el modelo con el tiempo.

#### Tareas T√©cnicas
- [ ] Crear componente `ScoreFeedback` en `components/candidates/ScoreFeedback.tsx`:
  ```tsx
  interface ScoreFeedbackProps {
    scoreId: UUID;
    onFeedback: (isAccurate: boolean, comment?: string) => void;
  }

  // UI: üëç / üëé buttons + optional comment modal
  ```
- [ ] Implementar modal para comentario opcional:
  - "¬øPor qu√© este score no es preciso?"
  - Opciones predefinidas + texto libre
- [ ] Implementar llamada a API de feedback
- [ ] Agregar toast de confirmaci√≥n
- [ ] Track feedback en analytics
- [ ] Escribir tests unitarios

#### Criterios de Aceptaci√≥n
- [ ] Feedback se env√≠a correctamente al backend
- [ ] Usuario puede a√±adir comentario opcional
- [ ] No se puede enviar feedback m√∫ltiple para mismo score
- [ ] Feedback enviado se refleja en UI (bot√≥n deshabilitado)

#### Definici√≥n de Done
- [ ] PR aprobado
- [ ] Tests unitarios pasando
- [ ] Analytics events configurados

#### Dependencias
- TK-006: API de feedback

#### Estimaci√≥n: 3 puntos de historia
#### Estimaci√≥n en horas: 6-8 horas

---

### Tickets DevOps/Infra

---

### TK-012: Configuraci√≥n de Vector Database (Pinecone)

**Tipo**: Infrastructure
**Componente**: Data Layer
**Prioridad**: Alta (Blocker)

#### Descripci√≥n
Configurar Pinecone como base de datos vectorial para almacenar embeddings de candidatos y ofertas, habilitando b√∫squeda sem√°ntica de skills.

#### Tareas T√©cnicas
- [ ] Crear index en Pinecone:
  ```
  Name: lti-embeddings-{env}
  Dimension: 1536 (OpenAI ada-002)
  Metric: cosine
  Pod type: s1 (starter) ‚Üí p2 (production)
  ```
- [ ] Configurar namespaces:
  - `skills`: embeddings de skills
  - `candidates`: embeddings de perfiles
  - `jobs`: embeddings de ofertas
- [ ] Implementar client wrapper en Python:
  ```python
  class VectorStore:
      async def upsert(self, vectors: List[Vector], namespace: str)
      async def query(self, vector: List[float], top_k: int, namespace: str)
      async def delete(self, ids: List[str], namespace: str)
  ```
- [ ] Configurar secrets en Kubernetes:
  - PINECONE_API_KEY
  - PINECONE_ENVIRONMENT
- [ ] Escribir tests de integraci√≥n
- [ ] Documentar estrategia de retention/cleanup

#### Criterios de Aceptaci√≥n
- [ ] Index creado en dev, staging, prod
- [ ] Client wrapper funcional con retry logic
- [ ] Latencia de query < 100ms p95
- [ ] Secrets configurados de forma segura
- [ ] Backup strategy documentada

#### Definici√≥n de Done
- [ ] Infrastructure as Code (Terraform) committeado
- [ ] Tests de integraci√≥n pasando
- [ ] Runbook de operaciones documentado

#### Estimaci√≥n: 5 puntos de historia
#### Estimaci√≥n en horas: 10-12 horas

---

### TK-013: Configuraci√≥n de M√©tricas y Alertas para AI Scoring

**Tipo**: DevOps
**Componente**: Observability
**Prioridad**: Media

#### Descripci√≥n
Configurar m√©tricas, dashboards y alertas espec√≠ficas para el sistema de AI Scoring, permitiendo monitorear performance, costos de LLM, y calidad de scores.

#### Tareas T√©cnicas
- [ ] Definir m√©tricas en Prometheus:
  ```yaml
  ai_scoring_duration_seconds: histogram
  ai_scoring_requests_total: counter (labels: status, model_version)
  ai_scoring_llm_tokens_used: counter (labels: provider, model)
  ai_scoring_llm_cost_usd: counter
  ai_scoring_accuracy_feedback: gauge (labels: feedback_type)
  ai_scoring_cache_hit_ratio: gauge
  ```
- [ ] Crear dashboard en Grafana:
  - Scoring throughput y latencia
  - LLM costs por d√≠a/semana
  - Distribuci√≥n de scores (histograma)
  - Feedback positivo vs negativo
  - Cache hit ratio
- [ ] Configurar alertas:
  - Latencia p95 > 30s ‚Üí Warning
  - Error rate > 5% ‚Üí Critical
  - LLM cost spike > 2x normal ‚Üí Warning
  - Feedback negativo > 30% ‚Üí Warning
- [ ] Configurar PagerDuty integration para critical alerts

#### Criterios de Aceptaci√≥n
- [ ] Dashboard funcional con datos reales
- [ ] Alertas disparan correctamente (tested)
- [ ] PagerDuty notifica al oncall
- [ ] Costo de LLM trackeable d√≠a a d√≠a

#### Definici√≥n de Done
- [ ] Dashboard en Grafana staging/prod
- [ ] Alertas configuradas y testeadas
- [ ] Runbook para cada alerta documentado

#### Dependencias
- TK-005, TK-006, TK-007 desplegados

#### Estimaci√≥n: 3 puntos de historia
#### Estimaci√≥n en horas: 6-8 horas

---

## Resumen de Tickets

| ID | T√≠tulo | Tipo | Estimaci√≥n (pts) | Estimaci√≥n (hrs) |
|----|--------|------|-----------------|-----------------|
| TK-001 | Modelo de Datos AI Score | Backend | 3 | 6-8h |
| TK-002 | SkillMatcher Component | Backend | 8 | 16-20h |
| TK-003 | ExperienceMatcher Component | Backend | 8 | 16-20h |
| TK-004 | CulturalFitAnalyzer Component | Backend | 5 | 10-12h |
| TK-005 | CandidateScorer Orchestrator | Backend | 8 | 16-20h |
| TK-006 | API REST para Scoring | Backend | 5 | 10-12h |
| TK-007 | Event Consumer Kafka | Backend | 5 | 10-12h |
| TK-008 | Componente AIScoreCard | Frontend | 5 | 10-12h |
| TK-009 | SkillsMatchDetail Component | Frontend | 3 | 6-8h |
| TK-010 | Integraci√≥n en Pipeline Kanban | Frontend | 5 | 10-12h |
| TK-011 | Componente Feedback | Frontend | 3 | 6-8h |
| TK-012 | Configuraci√≥n Pinecone | Infra | 5 | 10-12h |
| TK-013 | M√©tricas y Alertas | DevOps | 3 | 6-8h |

**Total: 66 puntos de historia**

---

## Diagrama de Dependencias

```mermaid
graph TD
    subgraph Infrastructure
        TK012[TK-012<br/>Pinecone Config]
    end

    subgraph "Backend - Components"
        TK001[TK-001<br/>Data Model]
        TK002[TK-002<br/>SkillMatcher]
        TK003[TK-003<br/>ExperienceMatcher]
        TK004[TK-004<br/>CulturalFit]
        TK005[TK-005<br/>CandidateScorer]
    end

    subgraph "Backend - API & Events"
        TK006[TK-006<br/>REST API]
        TK007[TK-007<br/>Kafka Consumer]
    end

    subgraph Frontend
        TK008[TK-008<br/>AIScoreCard]
        TK009[TK-009<br/>SkillsMatchDetail]
        TK010[TK-010<br/>Kanban Integration]
        TK011[TK-011<br/>Feedback Component]
    end

    subgraph DevOps
        TK013[TK-013<br/>Metrics & Alerts]
    end

    TK001 --> TK002
    TK001 --> TK003
    TK001 --> TK004
    TK012 --> TK002

    TK002 --> TK005
    TK003 --> TK005
    TK004 --> TK005

    TK005 --> TK006
    TK005 --> TK007

    TK006 --> TK008
    TK008 --> TK009
    TK008 --> TK010
    TK006 --> TK011

    TK006 --> TK013
    TK007 --> TK013

    classDef infra fill:#e1f5fe
    classDef backend fill:#fff3e0
    classDef frontend fill:#e8f5e9
    classDef devops fill:#f3e5f5

    class TK012 infra
    class TK001,TK002,TK003,TK004,TK005,TK006,TK007 backend
    class TK008,TK009,TK010,TK011 frontend
    class TK013 devops
```

---

## Plan de Sprints Sugerido

### Sprint 1 (Semana 1-2)
**Objetivo**: Foundations

| Ticket | Owner | Puntos |
|--------|-------|--------|
| TK-001 | Backend Dev | 3 |
| TK-012 | DevOps | 5 |
| TK-002 | Backend Dev | 8 |
| TK-008 | Frontend Dev | 5 |

**Total: 21 puntos**

### Sprint 2 (Semana 3-4)
**Objetivo**: Core Scoring

| Ticket | Owner | Puntos |
|--------|-------|--------|
| TK-003 | Backend Dev | 8 |
| TK-004 | Backend Dev | 5 |
| TK-005 | Backend Dev | 8 |

**Total: 21 puntos**

### Sprint 3 (Semana 5-6)
**Objetivo**: Integration & Polish

| Ticket | Owner | Puntos |
|--------|-------|--------|
| TK-006 | Backend Dev | 5 |
| TK-007 | Backend Dev | 5 |
| TK-009 | Frontend Dev | 3 |
| TK-010 | Frontend Dev | 5 |
| TK-011 | Frontend Dev | 3 |
| TK-013 | DevOps | 3 |

**Total: 24 puntos**

---

## Notas de Implementaci√≥n

### Consideraciones de Performance
- Usar batch processing para scoring de m√∫ltiples candidatos
- Implementar cache de embeddings de skills frecuentes
- Usar async/await para llamadas a LLM en paralelo

### Consideraciones de Seguridad
- No almacenar CV raw despu√©s de parsing (solo datos estructurados)
- Logs no deben contener PII
- Rate limiting estricto en endpoints de scoring

### Consideraciones de Testing
- Mock de LLM para tests unitarios (deterministic responses)
- Fixtures con CVs anonimizados para tests de integraci√≥n
- Load testing del batch endpoint antes de producci√≥n
